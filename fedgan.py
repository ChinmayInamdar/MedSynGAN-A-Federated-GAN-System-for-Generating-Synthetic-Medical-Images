# -*- coding: utf-8 -*-
"""FEDGAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O1aXCe5ypOYM3w3NtW2CEsJRzCp2GQSL
"""

import os
import torch
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import matplotlib.pyplot as plt
import torchvision

# Image transformations (Resizing and Normalization)
transform = transforms.Compose([
    transforms.Resize((64, 64)),       # Resize to 64x64
    transforms.ToTensor(),             # Convert to Tensor
    transforms.Normalize([0.5], [0.5]) # Normalize to [-1, 1]
])

# Custom Dataset class for NIH Chest X-rays
class ChestXrayDataset(Dataset):
    def __init__(self, labels_df, img_dir, transform=None):
        self.labels_df = labels_df
        self.img_dir = img_dir
        self.transform = transform

    def __len__(self):
        return len(self.labels_df)

    def __getitem__(self, idx):
        img_name = self.labels_df.iloc[idx, 0]  # Image name from CSV
        img_path = os.path.join(self.img_dir, img_name)
        image = Image.open(img_path).convert('L')  # Open as grayscale ('L')

        if self.transform:
            image = self.transform(image)

        return image

# Initialize Dataset and DataLoader
image_dir = '/home/user65/sample/images/'  # Change the path to your directory
dataset = ChestXrayDataset(labels_df, image_dir, transform=transform)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

# Example: Display a batch of preprocessed images
batch = next(iter(dataloader))
grid = torchvision.utils.make_grid(batch, nrow=8, normalize=True)
plt.imshow(grid.permute(1, 2, 0))
plt.show()

# Adding data augmentation to the transformations
transform_augmented = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.RandomHorizontalFlip(),    # Random horizontal flip
    transforms.RandomRotation(10),        # Random rotation
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

import cv2
import numpy as np

def apply_clahe(image):
    image_np = np.array(image)  # Convert PIL image to numpy array
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    image_clahe = clahe.apply(image_np)  # Apply CLAHE
    print("CLAHE applied to image.")

    # Convert back to PIL image
    return Image.fromarray(image_clahe)

# Example application
for img_tensor in batch:
    img = transforms.ToPILImage()(img_tensor)  # Convert Tensor to PIL
    img_clahe = apply_clahe(img)  # Apply CLAHE
    plt.imshow(img_clahe, cmap='gray')
    plt.show()
    break  # Display just one image

transform_random_affine = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

# Example application
for img_tensor in batch:
    img = transforms.ToPILImage()(img_tensor)
    img_affine = transform_random_affine(img)  # Apply random affine transform
    print("Random affine transform applied to image.")

    plt.imshow(img_affine.permute(1, 2, 0), cmap='gray')
    plt.show()
    break  # Display just one image

transform_contrast = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.ColorJitter(contrast=0.3),  # Random contrast adjustment
    transforms.ToTensor(),
    transforms.Normalize([0.5], [0.5])
])

# Example application
for img_tensor in batch:
    img = transforms.ToPILImage()(img_tensor)
    img_contrast = transform_contrast(img)  # Apply contrast jitter
    print("Random contrast applied to image.")

    plt.imshow(img_contrast.permute(1, 2, 0), cmap='gray')
    plt.show()
    break

from skimage import feature

def apply_canny(image):
    image_np = np.array(image)  # Convert PIL to numpy array
    edges = feature.canny(image_np / 255.0)  # Apply Canny edge detection
    print("Canny edge detection applied to image.")

    # Convert boolean edges array back to image
    return Image.fromarray((edges * 255).astype(np.uint8))

# Example application
for img_tensor in batch:
    img = transforms.ToPILImage()(img_tensor)
    img_canny = apply_canny(img)  # Apply Canny edge detection
    plt.imshow(img_canny, cmap='gray')
    plt.show()
    break

import torch
import torch.nn as nn

class Generator(nn.Module):
    def __init__(self, latent_dim):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            # Input is the latent space z, with size latent_dim
            nn.Linear(latent_dim, 128),
            nn.LeakyReLU(0.2),

            nn.Linear(128, 256),
            nn.BatchNorm1d(256),
            nn.LeakyReLU(0.2),

            nn.Linear(256, 512),
            nn.BatchNorm1d(512),
            nn.LeakyReLU(0.2),

            nn.Linear(512, 1024),
            nn.BatchNorm1d(1024),
            nn.LeakyReLU(0.2),

            nn.Linear(1024, 64 * 64),  # Output image size 64x64 flattened (64*64=4096 pixels)
            nn.Tanh()  # Tanh activation to output pixel values in range [-1, 1]
        )

    def forward(self, z):
        img = self.model(z)
        img = img.view(img.size(0), 1, 64, 64)  # Reshape to 1x64x64 for grayscale image
        return img

class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(64 * 64, 512),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),

            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),

            nn.Linear(256, 128),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),

            nn.Linear(128, 1),
            nn.Sigmoid()  # Sigmoid to output probability (real or fake)
        )

    def forward(self, img):
        img_flat = img.view(img.size(0), -1)  # Flatten the image
        validity = self.model(img_flat)
        return validity

import torch
import torch.nn as nn

# Hyperparameters
latent_dim = 100  # Size of the noise vector z
lr = 0.0002  # Learning rate for both networks
batch_size = 32  # Size of the image batch

# Define device: Use GPU if available, otherwise fallback to CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Assuming you have defined the Generator and Discriminator classes
# Initialize the Generator and Discriminator
generator = Generator(latent_dim).to(device)
discriminator = Discriminator().to(device)

# Optimizers for Generator and Discriminator
optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))
optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))

# Loss function (Binary Cross-Entropy loss)
adversarial_loss = nn.BCELoss()

import os
import torch
import matplotlib.pyplot as plt
import torchvision

# Directory to save checkpoints
checkpoint_dir = './checkpoints'
os.makedirs(checkpoint_dir, exist_ok=True)

# Number of epochs and other hyperparameters are assumed to be already defined
n_epochs = 200  # Number of training epochs
save_checkpoint_every = 10  # Save model checkpoints every 10 epochs

# Helper function to save model checkpoints
def save_checkpoint(epoch, generator, discriminator, optimizer_G, optimizer_D, g_loss, d_loss, checkpoint_dir):
    checkpoint_path = os.path.join(checkpoint_dir, f'gan_checkpoint_epoch_{epoch}.pth')
    torch.save({
        'epoch': epoch,
        'generator_state_dict': generator.state_dict(),
        'discriminator_state_dict': discriminator.state_dict(),
        'optimizer_G_state_dict': optimizer_G.state_dict(),
        'optimizer_D_state_dict': optimizer_D.state_dict(),
        'g_loss': g_loss,
        'd_loss': d_loss
    }, checkpoint_path)
    print(f"Checkpoint saved at epoch {epoch}")

# GAN Training Loop
for epoch in range(n_epochs):
    for i, imgs in enumerate(dataloader):

        # Training Discriminator
        real_imgs = imgs.to(device)  # Load a batch of real images
        batch_size = real_imgs.size(0)

        # Create labels for real and fake images
        valid = torch.ones(batch_size, 1, requires_grad=False).to(device)
        fake = torch.zeros(batch_size, 1, requires_grad=False).to(device)

        # Generate noise as input for the generator
        z = torch.randn(batch_size, latent_dim).to(device)

        # Generate a batch of fake images
        gen_imgs = generator(z)

        # Train Discriminator: maximize log(D(x)) + log(1 - D(G(z)))
        optimizer_D.zero_grad()
        real_loss = adversarial_loss(discriminator(real_imgs), valid)
        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)
        d_loss = (real_loss + fake_loss) / 2
        d_loss.backward()
        optimizer_D.step()

        # Training Generator: maximize log(D(G(z)))
        optimizer_G.zero_grad()
        g_loss = adversarial_loss(discriminator(gen_imgs), valid)  # Train G to fool the discriminator
        g_loss.backward()
        optimizer_G.step()

    # Print progress and save generated samples every few epochs
    print(f"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]")

    # Save generated images and checkpoints every few epochs
    if epoch % save_checkpoint_every == 0:
        with torch.no_grad():
            sample_z = torch.randn(25, latent_dim).to(device)
            gen_imgs = generator(sample_z)
            gen_imgs = gen_imgs * 0.5 + 0.5  # Rescale images from [-1, 1] to [0, 1]
            grid = torchvision.utils.make_grid(gen_imgs, nrow=5)
            plt.imshow(grid.permute(1, 2, 0).cpu().numpy())
            plt.show()

        # Save checkpoint
        save_checkpoint(epoch, generator, discriminator, optimizer_G, optimizer_D, g_loss, d_loss, checkpoint_dir)

# Save final model at the end of training
save_checkpoint(n_epochs, generator, discriminator, optimizer_G, optimizer_D, g_loss, d_loss, checkpoint_dir)